{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    # ISIS-affiliated tweets dataset\n",
    "    isis_df = pd.read_csv('isis_tweets.csv', sep=',')\n",
    "    isis_df.drop(['name', 'username', 'location', 'followers', 'numberstatuses', 'time', 'description'], axis=1, inplace=True)\n",
    "    isis_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Benign tweets dataset, truncated from 1.6M to 17k\n",
    "    benign_df = pd.read_csv('benign_tweets_2.csv', sep=',', header=None, nrows=17000)\n",
    "    benign_df.drop([0, 1, 2, 3, 4], axis=1, inplace=True)\n",
    "    benign_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge data and generate labels\n",
    "    data = np.concatenate((isis_df.as_matrix(), benign_df.as_matrix()))\n",
    "    labels = np.hstack((np.zeros(isis_df.shape[0]), np.ones(benign_df.shape[0])))\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli-distributed Naive-Bayes method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, vectorizer, X_train, y_train):\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def test(clf, vectorizer, X_test, y_test):\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "# For evaluation and debugging purposes\n",
    "def evaluate(X_train, y_train, X_test, y_test):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words='english', decode_error='ignore')\n",
    "    clf = BernoulliNB()\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data, run classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95640802092415"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = build_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train = X_train.transpose()[0]\n",
    "X_test = X_test.transpose()[0]\n",
    "\n",
    "evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
